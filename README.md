# Dymension

## Data store

The goal of the task is to design mechanism for synchronizing decentralized data storage.
But it does not define the structure of that store. Is it a filesystem, key-value store, database?

For the purpose of this design I assume that the data store is a binary blob of some fixed size.
This format might represent a large set of potential use cases. At the end of the day any data
are stored as byte blobs on some persistent block device.

The space is partitioned into N blocks, each containing 4KB of data. 4KB is selected because most of the
commonly used SSD drives today use that block size, meaning that reads and writes using that block size are most effective.

Each 4KB block in the blob is addressed using its index, which is the number in the range [0, N-1].
That way, it is efficient to access any block on the block device by using `seek` operation.
If the index is an unsigned 64-bit integer, it is possible to address 67108864 petabytes of data using this system.

## Proofs

System must provide data integrity. For that purpose, next to the data, merkle tree is stored, containing the hashes of the 4KB blocks.
There are two types of nodes in that tree:
- leaf nodes - containing a set of signatures generated by the sequencer for data blocks referenced by the leaf node (one signature per each data block)
- pointer nodes - containing hashes of leaf nodes or pointer nodes of the lower level

At the top, root node exists, containing the hash of the entire merkle tree.

Also, the list of all the root hashes must be stored, to be able to prove the data integrity
from the genesis state.

## Operation

Operation is a request to update the data store, produced by the sequencer every 0.2 seconds.
In the spec the term block is used for this purpose, but it collides with the same term I used above.

There are 150 operations (30 / 0.2) in every batch. For the purpose of this design I assumed that it is very unlikely
to observe two operations in the same batch touching the same data block.

Each operation broadcasted by a sequencer modifies some number of consequtive bytes in a single block.
The operation consists of:
- batch sequence (height)
- operation sequence in a batch (number from 0 to 149)
- block index
- offset in the block
- bytes to write (only the modified ones, not the entire data block)
- signature of all the above fields made using sequencer's private key

When the operation defined this way is executed by the full node:
1. signature, batch sequence and operation sequence are verified
2. block is read from the device (`seek` + `read`) and stored in the memory (4KB of data)
3. appropriate bytes are modified
4. block is written to the block device (`write`)
5. hash of the data block in the corresponding leaf node of the merkle tree is updated
6. leaf node of the merkle tree is marked as dirty

## End of batch

When batch is going to be finalized (all the operations has been broadcasted), sequencer broadcasts the commit message containing:
- batch sequence (height)
- hash of the merkle root
- signature of all the above fields made using sequencer's private key

When the commit message is processed by the full node:
- signature is verified
- all the dirty nodes inside merkle tree are recalculated up to the root node
- hash of the root node is compared to the one communicated inside the commit message
- read-only snapshot of the data is taken to serve light client requests

## Light client queries

When the light client needs to access the data, two variants are possible:
- light client trusts the full node
- light client doesn't trust the full node

In the trustful setup, the client simply asks the full node to respond with a scope of bytes
defined by the block index, offset and count.

In the trustless setup, the client must request full 4KB data block and all the relevant nodes
from the merkle tree, to be able to compute the proof of the state. The liht client might also track
or query for all the previous merkle tree hashes up to the genesis state. But it is more common to set
the trusted hash of some recent block when the light client is started for the first time.

## Updates optimization

It is defined that single operation is produced every 0.2 second but persistent state is generated once per 30 seconds,
aggregating all the operations from that period. It means, there are 150 operations to execute every 30 seconds.

The naive approach would be to aggregate all the operations inside the sequencer and then broadcast them at the end of the period.
That would mean that for 30 seconds the network does nothing, and then it is saturated by transferring tons of data.

Far better approach is to broadcast each operation immediately and let full nodes execute them as they come.
In this case full nodes must deal with temporary state (generated by the current batch) and persistent state
(generated at the end of the batch) used to generate responses for the requests received from the light clients.

To do that efficiently, the mechanism of snapshots must be implemented. Snapshotting is the huge topic on its own,
so I'm only mentioning here that BTRFS and ZFS filesystems are the good implementations.
For the purpose of this example, the data blob could be stored on such filesystem and snapshot could be taken every 150 operations
and mounted to serve the queries coming from the light clients.

## Synchronization

When not synchronized full node connects to the sequencer:
1. full nodes communicates the latest synchronized batch
2. sequencer computes the diff between reported batch and the latest ones and sends it to the full node
3. changes are applied
4. hash of the merkle tree is compared to the expected one

Probably it happens that in meantime, new batches are produced. It means that process must be repeated in a loop
until real-time data cover all the expected updates.

Obviously, if the process of synchronization is slower than the process of producing new batches then
full node won't be able to synchronize its state.

## Scalability

Sequencer communicates updates using unicast channel connected to each full node.
It means that, while number of full nodes grows, the bandwidth available to the sequencer saturates quickly.

To mitigate this, the network of distribution nodes might be created. In this scheme
sequencer broadcasts data to those distribution nodes, and they send data further to the full nodes.
Distribution nodes should be allocated across the world to allow full nodes to find the fastest one.

Many layers of distribution nodes might be created, or in extreme case, each full node might be a distribution node.
In this case all the full nodes form a mesh network.

In setups described above sequencer still must send the complete set of data to every node connected to it directly.
Alternatively, it could send a subset of operations to every connected node, saving on bandwidth.
In this case, full nodes must be connected to many distributed nodes to receive the full set of operations.
In this setup, the sequence of operations is no longer guaranteed by the TCP protocol, so operations must be cached, sorted
and processed in order.

## Latency

There is a trade-off between scalability and latency. Introducing intermediate nodes, increases latency
because there are more hops between the sequencer and full nodes. Each hop introduces delay caused by the processing time
required to receive, verify and broadcast the data.

## Security

### Data integrity

All the data broadcasted by the sequencer are signed using its private key. Sequencer's public key
is publicly known so al the full nodes might verify that data are legit even if they are received from some
intermediate node.

Obviously the sequencer is the source of the ground truth, meaning that its maintainer
may recalculate all the past batches and create new valid signatures. To mitigate it, the sequencer should be built out
of many nodes which must agree on signing data using some consensus protocol like pBFT.

### Liveness

It might happen that malicious intermediate node stops broadcasting the data.
To mitigate this full nodes and light clients should connect to many peers.
To save on bandwidth, connected peers could work in two modes: primary and secondary.
In primary mode, peer sends all the data. In secondary mode, peer might send only some headers
to notify others that operations are streamed.

By doing this, in case of malicious primary peer, connected nodes knows that data mnight be requested from other nodes.

### Network partitioning

Malicious sequencer could send different set of operations to different nodes.
In discussed setup it's possible because sequencer is a trusted party.
Full nodes might detect this, if they start receiving different sets of operations from connected peers,
being correctly signed by the sequencer.